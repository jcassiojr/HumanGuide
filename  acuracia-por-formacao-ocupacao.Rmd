---
title: "Classificação de Respondente"
author: "Cassio"
date: "Junho 15, 2016"
output: 
   html_document:
    fig_height: 4
    fig_width: 9.5
    number_sections: yes
    toc: yes
---

<center>![agileBIGDATA](./logoAgileBD.png)</center>

Este documento mostra os resultados de acurácia para o modleo aplicado nos dados do teste **Human Guide**.

# A Técnica Utilizada #

A técnica utilizada é largamente aplicada no campo de ciência de dados e é conhecida como **Machine Learning** (ver capítulo Referência). Basicamente consiste usar atributos dos dados para classificar os respondentes de alguma forma.
No nosso caso, a variável "formação" será a classificadora, ou target. Os componentes obtidos dos testes do Human Guide serão os atributos, ou preditores, usados para classificar os reapondentes.
Em outras palavras, usaremos os preditores para classificar os respondentes nas diferentes formações do escopo do Human Guide.

# A Preparação dos Dados #

Para implementar a técnica, usaremos os dados de 100.921 respostas do teste Human Guide.
De forma a tornar o modelo generalizável para outras amostras, os dados serão separados da seguinte forma:

+ dados de treino: 3/4 dos dados são separados aleatóriamente para treinarem o modelo, ou seja, prepará-lo para que consiga classificar os respondentesda forma mais eficiente.
+ dados de teste: 1/4 dos dados, os quais não foram usados para treinar o modelo, são separados para posterior validação da acurácia do modelo.

Para este treino dos dados foi usada uma técnica largamente usada para garantir o melhor resultado, chamada de **k-fold cross-validation**

# O Modelo Usado #

Foi usado o modelo de **Naive Bayes**, largamente usado em machine learning por seus bons resultados práticos.

# Validação do Modelo Usado #

Durante a validação do modelo, observou-se que o mesmo apresentou pontuação muito alta em *especificidade (TRUE NEGATIVE RATE)*, mas baixa em *sensitividade (TRUE POSITIVE RATE)*.

Em outras palavras, se o respondente obtém um percentual acima de 50% para uma dada formação (por exemplo, Direito), não podemos afirmar com certeza que ele tenha este perfil. Porém, se ele obtém pontuação abaixo de 50% para a mesma formação, podemos descartá-lacom uma ótima chance de acerto.

A acurácia mostrada abaixo é uma combinação das duas acurácias descritas acima.

**Nota:** os valores apresentados como **NA** são formações que não constavm nos dados usados para treinar o modelo e, portanto, não apresentam percentual previsto. O modelo pode ser treinado novamente em amostras posteriores onde constem estas formações dos respondentes, de forma a poder contê-las em sua previsão. 

A acurácia se apresenta diferente para cada formação em parte por não existirem quantidades diferentes de formações distribuidas nos dados. 
A medida que o modelo for "retreinado" com novas amostras mais completas, a tendência é a acurácia geral aumentar.
```{r, echo=FALSE, warning=FALSE}
#source("./R/f_assinatura_individual_HG.R") 
require("doMC", quietly = TRUE, warn.conflicts = FALSE)
require("dplyr", quietly = TRUE, warn.conflicts = FALSE)
require("xlsx", quietly = TRUE, warn.conflicts = FALSE)
registerDoMC(4) # parallel processing
```

```{r, echo=FALSE, warning=FALSE}
df_formacao <- read.csv2("./data/ref_formacao_sem_acento.csv", encoding = "Latin-1", 
                     sep = ",", header = FALSE)
names(df_formacao) <- c("cod.formacao", "desc.formacao")
df_acuracia <- data.frame(cod.formacao = seq(1,97), 
acuracia = c(.57, NA,.56,.58,.68,.58,.58,.61,.56,.66,              
             .53,.52,.57,.74,.50,.60,.58,.63,.59,.55,      
             .54,.60,.60,.59,.61,.57,.51,.67,.59,.68, #21-30
             .44,.46,.59,.64,.47,.66,.57,.58,.64,.70, #31-40
             .56,.89,.57,.64,.70,.61,.58,.66,.61,.47, #41-50
             .61,.55, NA, NA, NA, NA, NA, NA, NA, NA, #51-60
              NA, NA, NA, NA, NA, NA, NA, NA, NA,.70, #61-70
             .66,.66,.68,.67,.46,.65, NA,.40,.64,.62, #71-80
             .65,.63,.57,.63,.48,.56,.87,.54,.59,.61,  # ERRO AO RODAR 76
             .55,.75,.58,.56,.51,.59,.56
                ))

df_acur.form <- merge(df_formacao, df_acuracia, by = "cod.formacao")                           
write.xlsx2(df_acur.form, "./data/acuracia_previsoes.xlsx", row.names = FALSE)                            
knitr::kable(df_acur.form)
```

# Referências #

+ [Machine Learning] (https://en.wikipedia.org/wiki/Machine_learning)

+ [k-fold cross-validation] (https://en.wikipedia.org/wiki/Machine_learning)

+ [Naive Bayes] (https://en.wikipedia.org/wiki/Naive_Bayes_classifier)

+ [Sensitivite e Specificity] (https://en.wikipedia.org/wiki/Sensitivity_and_specificity)
