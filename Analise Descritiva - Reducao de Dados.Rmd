---
title: "Análise Descritiva - DRAFT"
author: "José Cassio"
date: "November 23, 2015"
output: html_document
---

![agileBIGDATA](./aBIG5.png)

Este documento descreve a análise descritiva realizada com o objetivo de reduzir as dimensões dos dados do teste **Human Guide** por meio da técnica de análise de componentes principais.

### Preparação dos dados ###
Foram obtidos os dados brutos das seguintes fontes:

* goe_20151121_0154.csv
* kroton_20151121_0125.csv
* rh99_20151121_0002.csv

Os arquivos acima foram concatenados, gerando 116.603 observações. 
Sobre estes dados brutos, foram aplicadas as fórmulas para a obtenção dos 8 fatores relevantes para a análise de componentes principais, gerando um arquivo de dados processados, cujas primeiras cinco linhas são mostradas abaixo:

```{r,echo=FALSE}
require("corrplot", quietly = TRUE, warn.conflicts = FALSE)
require("doMC", quietly = TRUE, warn.conflicts = FALSE)

#source("./R/f_le_raw_HG_ori.R") # usar esta função para ler os dados originais da tese. 
source("./R/f_le_raw_HG.R") # usar esta função para ler os dados novos. 
source("./R/f_tidy_scores_HG.R")

registerDoMC(5) # parallel processing
#df_raw_hg <- f_le_raw_HG_ori() # retorna colunas: ID, sexo, pontos
df_raw_hg <- f_le_raw_HG() # retorna colunas: todas
df_tidy_hg <- f_tidy_scores_HG(df_raw_hg)
#head(df_tidy_hg)
knitr::kable(head(df_tidy_hg))
```

### Análises Estatísticas Iniciais ###

A primeira análise a ser realizada consiste na obtenção de valores estatísticos básicos da amostra original:

#### Estatísticas Básicas da Amostra ####

```{r, echo=FALSE}
require("psych", quietly = TRUE, warn.conflicts = FALSE)
my.descr <- describe(df_tidy_hg[,3:10])
#print(my.descr)
knitr::kable(my.descr)
# hist(df_tidy_hg$power)
```

#### Análise de Correlação do Fatores ####

É realizada uma análise de correlação entre os 8 fatores, conforme os plots abaixo.

```{r, echo=FALSE}
my.cor <- cor(df_tidy_hg[,3:10])
corrplot.mixed(my.cor, insig = "p-value", sig.level = -1, is.corr = TRUE)
```

O plot acima mostra na metade superior a força da correlação entre os fatores, expressa por meio do tamanho do círculo e da intensidade de sua cor. Na parte inferior o **p-value** relcionado a medida de correlação.
A partir da tabela acima, pode ser observado um agrupamento aparente inicial:

    * G1: sensibility, exposure, structure e power
    * G2: imagination e stability
    * G3: contacts, quality e exposure

#### Outra Abordagem de Matriz de Correlação ####

```{r, echo=FALSE}
#pairs(df_tidy_hg[,3:10], main = "Matriz de Dispersão (feminino: green, masculino: red)", 
#          pch=21, bg=c("green3","red")[unclass(df_tidy_hg$sexo)])
# DESLIGANDO PROVISORIAMENTE ABAIXO POR DEMORAR MUITO (LIGAR NO DEFINITIVO)
#pairs(df_tidy_hg[,3:10], main = "Matriz de Dispersão (FUNC PUBLICO: green, KROTON: red, INDEFINIDO: blue, AMBEV: yellow)", 
#          pch=21, bg=c("green3","red", "blue", "yellow")[unclass(df_tidy_hg$TIPOUSER)])
```

#### Análise de Correlação do Fatores ####

É realizada uma análise de correlação entre os 8 fatores, conforme os plots abaixo:

```{r, echo=FALSE}
# correlação de spearman
    my.cor <- cor(df_tidy_hg[,3:10], method = "spearman")
    #print(my.cor, digits = 4)
    knitr::kable(my.cor)
```

#### Análise Cluster ####

Uma técnica não tão comum, mas particularmente útil em pesquisa psicológica, para redução de dados envolve agrupar as variáveis em clusters. Pode ser pensada como uma alternativa à Análise de Fatores, baseada em um modelo bem mais simples. 
É aplicada à amostra um algoritmo de análise de cluster (Item Cluster Analysis) usando princípios psycométricos para complementar as análises prévias, para 4 clusters. Clusters são combinados se os coeficientes *alfa (mean split half correlation)* e *beta (worst split half correlation)* aumantam para o próximo cluster.
Uma extensiva documentação e justificativa para o algoritmo pode ser encontrada no site 
*http://personality-project.org/revelle/publications/iclust.pdf*

```{r, echo=FALSE}
    ic <- iclust(my.cor, nclusters = 4) # usa Pearson correlation
    # summary(ic)
    print(ic)
```

A partir do resultado acima, pode-se também considerar a seguinte alternativa de agrupamento:

    * G1: structure e power
    * G2: sensibility e quality
    * G3: exposure e contacts
    * G4: imagination e stability

#### Análise de Componentes Principais ####

A análise de PCA foi implementada aos dados processados, gerando oito componentes, associados aos seguintes resultados normalizados:

##### Desvio Padrão associado aos Componentes #####

```{r, echo=FALSE}
    pca1 = prcomp(df_tidy_hg[,3:10], scale. = TRUE, center = TRUE)
    print (pca1$sdev)
    #knitr::kable(pca1$sdev)
```

##### *Loadings* ou *Rotations* ##### 

Cada componente sendo uma combinação linear das variáveis (8 fatores). Os coeficientes indicando o quanto cada variável está correlacionada com os componentes específicos:

```{r, echo=FALSE}
    # pca1$rotation
    knitr::kable(pca1$rotation)
```

##### Scores ##### 
Os scores são calculados a partir da recombinação dos originais 8 fatores nos novos componentes. Abaixo são mostrados os cinco primeiros scores de todas as observações, associados aos novos componentes:
```{r, echo=FALSE}
    # head(pca1$x)
    #knitr::kable(head(pca1$x), digits = 4)
    knitr::kable(head(pca1$x))
```

##### Sumário da análise PCA ##### 
Abaixo está o sumário da análise PCA executada, mostrando a importância da contribuição de cada componente:
```{r, echo=FALSE}
    summary(pca1)
```

#### Redução dos Componentes Principais ####

##### Redução pelo critério de Kaiser ##### 

Um critério que pode ser usado para reduzir os componentes é o de selecionar apenas aqueles com eigenvalues maior que 1 (critério de Kaiser).
```{r, echo=FALSE}
    my.kayser.crit <- pca1$sdev ^ 2
    #knitr::kable(my.kayser.crit)
    print(my.kayser.crit)
```

Caso se opte pelo critério acima, deve-se considerar os cinco primeiros componentes no prosseguimento da análise 

##### Redução pelo Scree plot ##### 

Um outro critério que pode ser usado para reduzir os componentes é o plotar as variações dos componentes e visualmente selecionar aqueles que têm a maior contribuição nesta variação:

```{r, echo=FALSE}
    screeplot(pca1, main = "Scree Plot - Human Guide", type = "lines")
```

Nesta abordagem, pode-se identificar um patamar inicial levemente destacado com os quatro primeiros componentes sendo mais significativos e um segundo patamar mais destacado com os sete primeiros componentes. No caso do primeiro patamar, verifica-se que estes componentes são responsáveis por cerca de *64%* da variação dos dados. 

#### Aplicando a rotação Varimax para interpretar os componentes ####

A rotação muda as coordenadas de forma a maximizar a soma das variâncias dos quadrados dos *loadings*, desta forma realizando uma "limpeza" nas rotações obtidas originalmente na análise PCA.
Esta rotação é usada para ajudar na melhor interpretação dos componentes, de forma a identificar significado nos mesmos.

Opta-se, neste caso, pelo uso de 4 componentes para a rotação, de acordo com o observado no primeiro patamar do scree plot.

```{r, echo=FALSE}
    varimax <- varimax(pca1$rotation[,1:4], normalize = TRUE)
    print (varimax$loadings)
```

##### Plotando os fatores de acordo com os componentes após a rotação ##### 

O plot abaixo mostra os eigenvalues dos fatores em relação aos pares de componentes encontrados.
Obs: no momento somente para os 3 primeiros componentes (complementar a documentação final com todas as combinações)

##### Componentes PC1 e PC2 #####

```{r, echo=FALSE}
    require("ggplot2", quietly = TRUE, warn.conflicts = FALSE)
    my.var_load <- varimax$loadings[1:8,]
    loadings <- data.frame(my.var_load, .names = row.names(pca1$rotation))
    theta <- seq(0,2*pi,length.out = 100)
    circle <- data.frame(x = cos(theta), y = sin(theta))
    
    # plot após rotação PC1 x PC2
    #----------------------------
    p <- ggplot(circle,aes(x,y)) + geom_path()
    p + geom_text(data=loadings, 
              mapping=aes(x = PC1, y = PC2, label = "a", colour = .names)) +
    coord_fixed(ratio=1) +
    labs(x = "PC1", y = "PC2")
```

##### Componentes PC2 e PC3 #####

```{r, echo=FALSE}
    p <- ggplot(circle,aes(x,y)) + geom_path()
    p + geom_text(data=loadings, 
                  mapping=aes(x = PC2, y = PC3, label = "a", colour = .names)) +
        coord_fixed(ratio=1) +
        labs(x = "PC2", y = "PC3")
```

##### Componentes PC3 e PC4 #####

```{r, echo=FALSE}
    p <- ggplot(circle,aes(x,y)) + geom_path()
    p + geom_text(data=loadings, 
                  mapping=aes(x = PC1, y = PC3, label = "a", colour = .names)) +
        coord_fixed(ratio=1) +
        labs(x = "PC1", y = "PC3")
```

#### Plotando os fatores de acordo com os componentes após a rotação em formato 3D ####

##### Base PC3 #####

```{r, echo=FALSE}
    library(scatterplot3d)
    df_varload <- as.data.frame(my.var_load)
    with(df_varload, {
        s3d <- scatterplot3d(PC1, PC2, PC3,        # x y and z axis
                             color="blue", pch=19,        # filled blue circles
                             type="h",                    # vertical lines to the x-y plane
                             main="3-D Component Plot in Rotated Space (Base PC3)",
                             xlab="PC1",
                             ylab="PC2",
                             zlab="PC3")
        s3d.coords <- s3d$xyz.convert(PC1, PC2, PC3) # convert 3D coords to 2D projection
        text(s3d.coords$x, s3d.coords$y,             # x and y coordinates
             labels=row.names(df_varload),               # text to plot
             cex=.5, pos=4)           # shrink text 50% and place to right of points)
    })
```

##### Base PC2 #####

```{r, echo=FALSE}
      with(df_varload, {
        s3d <- scatterplot3d(PC3, PC1, PC2,         # x y and z axis
                             color="blue", pch=19,        # filled blue circles
                             type="h",                    # vertical lines to the x-y plane
                             main="3-D Component Plot in Rotated Space (Base PC2)",
                             xlab="PC3",
                             ylab="PC1",
                             zlab="PC2")
        s3d.coords <- s3d$xyz.convert(PC3, PC1, PC2) # convert 3D coords to 2D projection
        text(s3d.coords$x, s3d.coords$y,             # x and y coordinates
             labels=row.names(df_varload),               # text to plot
             cex=.5, pos=4)           # shrink text 50% and place to right of points)
    })
```

##### Base PC1 #####

```{r, echo=FALSE}
    with(df_varload, {
        s3d <- scatterplot3d(PC2, PC3, PC1,         # x y and z axis
                             color="blue", pch=19,        # filled blue circles
                             type="h",                    # vertical lines to the x-y plane
                             main="3-D Component Plot in Rotated Space (Base PC1)",
                             xlab="PC2",
                             ylab="PC3",
                             zlab="PC1")
        s3d.coords <- s3d$xyz.convert(PC2, PC3, PC1) # convert 3D coords to 2D projection
        text(s3d.coords$x, s3d.coords$y,             # x and y coordinates
             labels=row.names(df_varload),               # text to plot
             cex=.5, pos=4)           # shrink text 50% and place to right of points)
    })
```

### Prevendo Scores de Novas Amostras ###

A partir do modelo obtido com a Análise de Componentes Principais é possível posicionar novos candidatos em relação a seus scores nos componentes, conforme exemplificado abaixo, para 1000 candidatos da amostra selecionados aleatóriamente.

Considerando a pontuação dos candidatos abaixo (como amostra, mostramos somente os 10 primeiros):

```{r, echo=FALSE}
    #my.newdata <- head(df_tidy_hg[,c(1,2,3:10)])
    my.newdata <- 
        df_tidy_hg %>%
        sample_n(1000)

    #print (my.newdata)
    knitr::kable(head(my.newdata, n = 10))
```

Aplicando o modelo, podemos obter os seguintes scores (como amostra, mostramos somente os 10 primeiros):
```{r, echo=FALSE}
    # colocar aqui a diferenciação por cor e plotar os valores com as cores em 3D
    my.prev <- as.data.frame(predict(pca1, newdata=my.newdata))
    my.prev <- cbind(my.newdata, PC1 = my.prev$PC1, PC2 = my.prev$PC2, PC3 = my.prev$PC3)
    #print(my.prev[,c(1,10:12)])
    knitr::kable(head(my.prev[,c(1,2,11:13)], n = 10))
```

Considerando com cores direrentes os tipos de usuários: KROTNO, AMBEV e FUNCIONÁRIO PÚBLICO, o gráfico abaixo permite uma análise das distribuições das previsões por tipo de usuário
```{r, echo=FALSE}
# aplicando a HG
library(scatterplot3d)
# create column indicating point color
my.prev$pcolor[my.prev$TIPOUSER=="FUNC PUBLICO"] <- "red"
my.prev$pcolor[my.prev$TIPOUSER=="AMBEV"] <- "blue"
my.prev$pcolor[my.prev$TIPOUSER=="KROTON"] <- "green3"
                         
with(my.prev, {
    s3d <- scatterplot3d(PC1, PC2, PC3,
                         color=pcolor, pch=19,
                         type="h", lty.hplot=2,
                         scale.y=.75,
                         main="3-D Scatterplot Human Guide",
                         xlab="PC1",
                         ylab="PC2",
                         zlab="PC3")
    s3d.coords <- s3d$xyz.convert(PC1, PC2, PC3)
    # comentar as 3 linhas abaixo para eliminar o ID como label dos pontos (somente cores)
    #text(s3d.coords$x, s3d.coords$y,
    #     labels=row.names(my.prev),
    #     pos=4, cex=.5)
    legend("topright", inset=.05,
           bty="n", cex=.5,
           title="Tipo do Usuário",
           c("FUNC PUBLICO", "AMBEV", "KROTON"), fill=c("red", "blue", "green"))
})
```


A saída acima pode ser aplicada a um algoritmo para classificar candidato nos componentes associados.
